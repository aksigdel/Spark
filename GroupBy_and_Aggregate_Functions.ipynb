{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWRQOPfjO9oH",
        "outputId": "af7fb96d-48d7-4e87-d0c2-e1f04a21ef6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 64 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 71.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=074551dab80fcf9c577f0b0efda6798776017d3706cfe07bc8dc595c6627fb13\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8BTHVK3LpPf"
      },
      "source": [
        "# GroupBy and Aggregate Functions\n",
        "\n",
        "Let's learn how to use GroupBy and Aggregate methods on a DataFrame. GroupBy allows you to group rows together based off some column value, for example, you could group together sales data by the day the sale occured, or group repeast customer data based off the name of the customer. Once you've performed the GroupBy operation you can use an aggregate function off that data. An aggregate function aggregates multiple rows of data into a single output, such as taking the sum of inputs, or counting the number of inputs.\n",
        "\n",
        "Let's see some examples on an example dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "noYsCPP3LpPp",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "FvGkSTVHLpPr",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# May take a little while on a local computer\n",
        "spark = SparkSession.builder.appName(\"groupbyagg\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwffki62LpPs"
      },
      "source": [
        "Read in the customer sales data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "Rke-fVJkLpPt",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('sample_data/sales_info.csv',inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "01jiX6yhLpPt",
        "outputId": "5ac574b5-d033-494c-e1c1-05365a86f4a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Company: string (nullable = true)\n",
            " |-- Person: string (nullable = true)\n",
            " |-- Sales: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lzEvVN0lLpPv",
        "outputId": "704af85c-9f51-4382-f2ec-adb240a71fab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+\n",
            "|Company| Person|Sales|\n",
            "+-------+-------+-----+\n",
            "|   GOOG|    Sam|200.0|\n",
            "|   GOOG|Charlie|120.0|\n",
            "|   GOOG|  Frank|340.0|\n",
            "|   MSFT|   Tina|600.0|\n",
            "|   MSFT|    Amy|124.0|\n",
            "|   MSFT|Vanessa|243.0|\n",
            "|     FB|   Carl|870.0|\n",
            "|     FB|  Sarah|350.0|\n",
            "|   APPL|   John|250.0|\n",
            "|   APPL|  Linda|130.0|\n",
            "|   APPL|   Mike|750.0|\n",
            "|   APPL|  Chris|350.0|\n",
            "+-------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID603T34LpPw"
      },
      "source": [
        "Let's group together by company!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e8pWa5_5LpPx",
        "outputId": "334564f8-6f00-4139-c79d-a2bd030b859f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.group.GroupedData at 0x7f7add7e08d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#groupby 'Company'\n",
        "df.groupBy(\"Company\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLgUfx3cLpPy"
      },
      "source": [
        "This returns a GroupedData object, off of which you can all various methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KL4iGFgMLpPz",
        "outputId": "7cf8e42d-7ef5-41dd-d299-3652ab6ad63e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|Company|       avg(Sales)|\n",
            "+-------+-----------------+\n",
            "|   APPL|            370.0|\n",
            "|   GOOG|            220.0|\n",
            "|     FB|            610.0|\n",
            "|   MSFT|322.3333333333333|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# groupby 'Company' and take Mean\n",
        "df.groupBy(\"Company\").mean().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bbInHhbRLpP0",
        "outputId": "474e518c-5d99-4df8-ccac-7854d9ab23ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|Company|count|\n",
            "+-------+-----+\n",
            "|   APPL|    4|\n",
            "|   GOOG|    3|\n",
            "|     FB|    2|\n",
            "|   MSFT|    3|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# groupby 'Company' and take count\n",
        "df.groupBy(\"Company\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FWBB9E0tLpP2",
        "outputId": "ea65b427-8c7d-4bf2-e718-084bf450e9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|Company|max(Sales)|\n",
            "+-------+----------+\n",
            "|   APPL|     750.0|\n",
            "|   GOOG|     340.0|\n",
            "|     FB|     870.0|\n",
            "|   MSFT|     600.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# groupby 'Company' and take max\n",
        "df.groupBy(\"Company\").max().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b8YTRfBpLpP3",
        "outputId": "74391c9c-1991-4016-e81f-7ae2abe065c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|Company|min(Sales)|\n",
            "+-------+----------+\n",
            "|   APPL|     130.0|\n",
            "|   GOOG|     120.0|\n",
            "|     FB|     350.0|\n",
            "|   MSFT|     124.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# groupby 'Company' and take Min\n",
        "df.groupBy(\"Company\").min().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WA6VhkL2LpP4",
        "outputId": "0a011c07-e88e-41af-837a-47637864ef50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|Company|sum(Sales)|\n",
            "+-------+----------+\n",
            "|   APPL|    1480.0|\n",
            "|   GOOG|     660.0|\n",
            "|     FB|    1220.0|\n",
            "|   MSFT|     967.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# groupby 'Company' and take Sum\n",
        "df.groupBy(\"Company\").sum().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv25uTiBLpP5"
      },
      "source": [
        "Check out this link for more info on other methods:\n",
        "http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark-sql-module\n",
        "\n",
        "Not all methods need a groupby call, instead you can just call the generalized .agg() method, that will call the aggregate across all rows in the dataframe column specified. It can take in arguments as a single column, or create multiple aggregate calls all at once using dictionary notation.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mq63s3e0LpP6",
        "outputId": "d80c21b3-b479-4d0a-ffb7-b132e8ad3ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|max(Sales)|\n",
            "+----------+\n",
            "|     870.0|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# aggregrate max sales across everything\n",
        "\n",
        "df.agg({'Sales':'max'}).show()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "c-2vBtJLLpP7",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f30757a-ced0-41e5-d3cc-98447f7c76cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|Company|max(Sales)|\n",
            "+-------+----------+\n",
            "|   APPL|     750.0|\n",
            "|   GOOG|     340.0|\n",
            "|     FB|     870.0|\n",
            "|   MSFT|     600.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Could have done this on the group by object as well:\n",
        "df.groupBy(\"Company\").agg({'Sales':'max'}).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "TP8GZpyoLpP7",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# groupby company\n",
        "grouped = df.groupBy(\"Company\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZnLsB_bcLpP8",
        "outputId": "5bc911e1-48d8-481c-a888-60706d4dec3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|Company|max(Sales)|\n",
            "+-------+----------+\n",
            "|   APPL|     750.0|\n",
            "|   GOOG|     340.0|\n",
            "|     FB|     870.0|\n",
            "|   MSFT|     600.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#aggregrate max sales across everything\n",
        "grouped.agg({'Sales':'max'}).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15V9wwvXLpP9"
      },
      "source": [
        "## Functions\n",
        "There are a variety of functions you can import from pyspark.sql.functions. Check out the documentation for the full list available:\n",
        "http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XKnGEr7YLpP9"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import countDistinct, avg,stddev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nvEBo-ukLpP-",
        "outputId": "f8f32f2b-f103-4b7d-8c0e-38d3b562138a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|count(DISTINCT Sales)|\n",
            "+---------------------+\n",
            "|                   11|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# count DISTINCT sales and show\n",
        "df.select(countDistinct(\"Sales\")).show()   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzhhMKsULpP_"
      },
      "source": [
        "Often you will want to change the name, use the .alias() method for this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "R98yE3DnLpP_",
        "outputId": "699568e1-847d-456a-9578-5987d89df33c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|Distinct Sales|\n",
            "+--------------+\n",
            "|            11|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# doing same and aliasing using alias to show 'Distinct Sales'\n",
        "df.select(countDistinct(\"Sales\").alias(\"Distinct Sales\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ntxGjqHULpQA",
        "outputId": "d9699f65-7b69-45fb-c5c8-a76c16678d76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|       avg(Sales)|\n",
            "+-----------------+\n",
            "|360.5833333333333|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# select average sales\n",
        "df.select(avg(\"Sales\")).show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZY1QQ65LLpQA",
        "outputId": "4ddabe57-3bc2-4845-acb8-24a0ea537695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|stddev_samp(Sales)|\n",
            "+------------------+\n",
            "|250.08742410799007|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# select standard deviation of sales\n",
        "df.select(stddev(\"Sales\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ13fxYLLpQB"
      },
      "source": [
        "That is a lot of precision for digits! Let's use the format_number to fix that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "gF7L0PTCLpQB",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import format_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "rOaOqr_9LpQB",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# getting the standard deviation and aliasing it\n",
        "sales_std = df.select(stddev(\"Sales\").alias('std'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8VCzB3VdLpQC",
        "outputId": "220bbc83-ed11-4cb5-fc10-65c8ceb8e8a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|               std|\n",
            "+------------------+\n",
            "|250.08742410799007|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sales_std.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZrXLy3TDLpQC",
        "outputId": "e0522fd8-752f-4c89-da3b-4d904e195ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|format_number(std, 2)|\n",
            "+---------------------+\n",
            "|               250.09|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# format_number(\"col_name\",decimal places)\n",
        "sales_std.select(format_number('std',2)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUwVvHMELpQD"
      },
      "source": [
        "## Order By\n",
        "\n",
        "You can easily sort with the orderBy method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YykDAC8QLpQD",
        "outputId": "0e4687c2-c198-4b98-b948-234a7d9ed8e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+\n",
            "|Company| Person|Sales|\n",
            "+-------+-------+-----+\n",
            "|   GOOG|Charlie|120.0|\n",
            "|   MSFT|    Amy|124.0|\n",
            "|   APPL|  Linda|130.0|\n",
            "|   GOOG|    Sam|200.0|\n",
            "|   MSFT|Vanessa|243.0|\n",
            "|   APPL|   John|250.0|\n",
            "|   GOOG|  Frank|340.0|\n",
            "|     FB|  Sarah|350.0|\n",
            "|   APPL|  Chris|350.0|\n",
            "|   MSFT|   Tina|600.0|\n",
            "|   APPL|   Mike|750.0|\n",
            "|     FB|   Carl|870.0|\n",
            "+-------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# OrderBy\n",
        "# Ascending by 'Sales'\n",
        "df.orderBy(\"Sales\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jxNXgus9LpQE",
        "outputId": "d843caf8-c23e-44e9-c0cd-2becc8e9eec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+\n",
            "|Company| Person|Sales|\n",
            "+-------+-------+-----+\n",
            "|     FB|   Carl|870.0|\n",
            "|   APPL|   Mike|750.0|\n",
            "|   MSFT|   Tina|600.0|\n",
            "|     FB|  Sarah|350.0|\n",
            "|   APPL|  Chris|350.0|\n",
            "|   GOOG|  Frank|340.0|\n",
            "|   APPL|   John|250.0|\n",
            "|   MSFT|Vanessa|243.0|\n",
            "|   GOOG|    Sam|200.0|\n",
            "|   APPL|  Linda|130.0|\n",
            "|   MSFT|    Amy|124.0|\n",
            "|   GOOG|Charlie|120.0|\n",
            "+-------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Descending call off the column itself for 'Sales'\n",
        "df.orderBy(df[\"Sales\"].desc()).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDydcthrLpQE"
      },
      "source": [
        "Most basic functions you would expect to be available are, so make sure to check out the documentation!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}